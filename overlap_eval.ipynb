{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ncoop57/t5_overlap/blob/main/overlap_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading https://files.pythonhosted.org/packages/52/b9/d426f164f35bb50d512a77d6a7c5eb70b2bea3459dc10f73f130ba732810/gdown-3.13.0.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock (from gdown)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n",
      "Requirement already satisfied: requests[socks]>=2.12.0 in /opt/conda/lib/python3.6/site-packages (from gdown) (2.21.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from gdown) (1.12.0)\n",
      "Collecting tqdm (from gdown)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 7.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests[socks]>=2.12.0->gdown) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests[socks]>=2.12.0->gdown) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests[socks]>=2.12.0->gdown) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests[socks]>=2.12.0->gdown) (1.24.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /opt/conda/lib/python3.6/site-packages (from requests[socks]>=2.12.0->gdown) (1.6.8)\n",
      "Building wheels for collected packages: gdown\n",
      "  Running setup.py bdist_wheel for gdown ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/ba/fa/c5/12813d7496f34652c43a471e11a780e769889d06e34735c32e\n",
      "Successfully built gdown\n",
      "Installing collected packages: filelock, tqdm, gdown\n",
      "Successfully installed filelock-3.0.12 gdown-3.13.0 tqdm-4.60.0\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zKW5bOMjKHfX75d_uz8OF2teTb5Dse_M\n",
      "To: /home/jovyan/work/datasets.zip\n",
      "869MB [00:13, 64.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1EFPcdIpl-uez4e0918Yk4hQrLRyGczxf\n",
      "To: /home/jovyan/work/DataSnooping_Analysis_Data.zip\n",
      "15.9MB [00:00, 63.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KBVkhFZ80i1PW80aZexFGvJjyEClelX1\n",
      "To: /home/jovyan/work/dl4se_vocab.model\n",
      "100%|████████████████████████████████████████| 795k/795k [00:00<00:00, 18.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "! pip install gdown sentencepiece\n",
    "! gdown https://drive.google.com/uc?id=1zKW5bOMjKHfX75d_uz8OF2teTb5Dse_M\n",
    "! gdown https://drive.google.com/uc?id=1EFPcdIpl-uez4e0918Yk4hQrLRyGczxf\n",
    "! gdown https://drive.google.com/uc?id=1KBVkhFZ80i1PW80aZexFGvJjyEClelX1\n",
    "! unzip datasets.zip\n",
    "! unzip DataSnooping_Analysis_Data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PSoyEedH6Cf2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "fine_tune_path = Path(\"datasets/tsv/fine-tuning\")\n",
    "\n",
    "def get_agab_dfs():\n",
    "    trn_agab_df = pd.read_csv(\n",
    "        fine_tune_path/\"AGabs/training.tsv\", sep=\"\\t\", \n",
    "        names=[\"input\", \"target\"]\n",
    "    )\n",
    "    tst_agab_df = pd.read_csv(\n",
    "        \"DataSnooping_Analysis_Data/AGabs.csv\", index_col=0\n",
    "    ).sort_values(\"IS_Perfect\")\n",
    "\n",
    "    return trn_agab_df, tst_agab_df\n",
    "\n",
    "def get_agraw_dfs():\n",
    "    trn_agraw_df = pd.read_csv(\n",
    "        fine_tune_path/\"AGraw/training.tsv\", sep=\"\\t\",\n",
    "        names=[\"input\", \"target\"]\n",
    "    )\n",
    "    tst_agraw_df = pd.read_csv(\n",
    "        \"DataSnooping_Analysis_Data/AGraw.csv\", index_col=0\n",
    "    ).sort_values(\"IS_Perfect\")\n",
    "\n",
    "    return trn_agraw_df, tst_agraw_df\n",
    "\n",
    "def get_bfsm_dfs():\n",
    "    trn_bfsm_df = pd.read_csv(\n",
    "        \"datasets/tsv/fine-tuning/BFsmall/training.tsv\", sep=\"\\t\",\n",
    "        names=[\"input\", \"target\"]\n",
    "    )\n",
    "    tst_bfsm_df = pd.read_csv(\n",
    "        \"DataSnooping_Analysis_Data/BFsmall.csv\", index_col=0\n",
    "    ).sort_values(\"IS_Perfect\")\n",
    "\n",
    "    return trn_bfsm_df, tst_bfsm_df\n",
    "\n",
    "def get_bfmed_dfs():\n",
    "    trn_bfmed_df = pd.read_csv(\n",
    "        \"datasets/tsv/fine-tuning/BFmedium/training.tsv\", sep=\"\\t\",\n",
    "        names=[\"input\", \"target\"]\n",
    "    )\n",
    "    tst_bfmed_df = pd.read_csv(\n",
    "        \"DataSnooping_Analysis_Data/BFmedium.csv\", index_col=0\n",
    "    ).sort_values(\"IS_Perfect\")\n",
    "\n",
    "    return trn_bfmed_df, tst_bfmed_df\n",
    "\n",
    "def get_codesum_dfs():\n",
    "    trn_codesum_df = pd.read_csv(\n",
    "        \"datasets/tsv/fine-tuning/CS/training.tsv\", sep=\"\\t\",\n",
    "        names=[\"input\", \"target\"]\n",
    "    )\n",
    "    tst_codesum_df = pd.read_csv(\n",
    "        \"DataSnooping_Analysis_Data/CodeSummarization.csv\", index_col=0\n",
    "    ).sort_values(\"BLEU\")\n",
    "\n",
    "    return trn_codesum_df, tst_codesum_df\n",
    "\n",
    "def get_muts_dfs():\n",
    "    trn_muts_df = pd.read_csv(\n",
    "        \"datasets/tsv/fine-tuning/MG/training.tsv\", sep=\"\\t\",\n",
    "        names=[\"input\", \"target\"]\n",
    "    )\n",
    "    tst_muts_df = pd.read_csv(\n",
    "        \"DataSnooping_Analysis_Data/Mutants.csv\", index_col=0\n",
    "    ).sort_values(\"BLEU\")\n",
    "\n",
    "    return trn_muts_df, tst_muts_df\n",
    "\n",
    "def sample_bst_wrst(df, pop=1_000, n=100):\n",
    "    bst = df.tail(pop)\n",
    "    wrst = df.head(pop)\n",
    "\n",
    "    return bst.sample(n), wrst.sample(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bSGy7-SeHcbd"
   },
   "outputs": [],
   "source": [
    "# This code was taken from https://gist.github.com/kylebgorman/1081951/bce3de986e4b05fc0b63d4d9e0cfa4bde6664365\n",
    "def _dist(A, B, insertion, deletion, substitution):\n",
    "    D = np.zeros((len(A) + 1, len(B) + 1))\n",
    "    for i in range(len(A)):\n",
    "        D[i + 1][0] = D[i][0] + deletion\n",
    "    for j in range(len(B)):\n",
    "        D[0][j + 1] = D[0][j] + insertion\n",
    "    for i in range(len(A)): # fill out middle of matrix\n",
    "        for j in range(len(B)):\n",
    "            if A[i] == B[j]:\n",
    "                D[i + 1][j + 1] = D[i][j] # aka, it's free.\n",
    "            else:\n",
    "                D[i + 1][j + 1] = min(D[i + 1][j] + insertion,\n",
    "                                      D[i][j + 1] + deletion,\n",
    "                                      D[i][j]     + substitution)\n",
    "    return D\n",
    "\n",
    "def levenshtein_distance(l1, l2, normalize=False):\n",
    "    dist = _dist(l1, l2, 1, 1, 1)[-1][-1]\n",
    "    if normalize:\n",
    "        return 1. - dist / max(len(l1), len(l2))\n",
    "    else:\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eT5XvEzsLRmh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import scipy.stats as st\n",
    "from statistics import mean, median, stdev\n",
    "\n",
    "def get_dists(trn, tst):\n",
    "    import sentencepiece as spm\n",
    "    s = spm.SentencePieceProcessor(model_file='dl4se_vocab.model')\n",
    "    s.encode(\"public static void main\", out_type=str)\n",
    "    dists = Parallel(n_jobs=-1)(\n",
    "        delayed(levenshtein_distance)(s.encode(i), s.encode(j))\n",
    "        for i in trn for j in tst\n",
    "    )\n",
    "    \n",
    "    return dists\n",
    "\n",
    "# From https://stackoverflow.com/a/51288518/5768407 by Yetti\n",
    "def ci_overlap(start1, end1, start2, end2):\n",
    "    \"\"\"how much does the range (start1, end1) overlap with (start2, end2)\"\"\"\n",
    "    return max(max((end2-start1), 0) - max((end2-end1), 0) - max((start2-start1), 0), 0)\n",
    "\n",
    "def run_experiments(data_func, n_exp=100, pop=1_000, n_samp=100, alpha = 0.95):\n",
    "    bst_dists = []\n",
    "    wrst_dists = []\n",
    "\n",
    "    trn_df, tst_df = data_func()\n",
    "    for _ in range(n_exp):\n",
    "        (trn_bst, trn_wrst), (tst_bst, tst_wrst) = sample_bst_wrst(trn_df, pop, n_samp), sample_bst_wrst(tst_df, pop, n_samp)\n",
    "        bst_dists.extend(get_dists(trn_bst[\"target\"].values, tst_bst[\"Groundtruth\"].values))\n",
    "        wrst_dists.extend(get_dists(trn_wrst[\"target\"].values, tst_wrst[\"Groundtruth\"].values))\n",
    "\n",
    "    bst_ci = st.t.interval(\n",
    "        alpha=alpha, df=len(bst_dists)-1,\n",
    "        loc=np.mean(bst_dists),\n",
    "        scale=st.sem(bst_dists)\n",
    "    )\n",
    "    wrst_ci = st.t.interval(\n",
    "        alpha=alpha, df=len(wrst_dists)-1,\n",
    "        loc=np.mean(wrst_dists),\n",
    "        scale=st.sem(wrst_dists)\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"best\": {\n",
    "            \"dists\": bst_dists,\n",
    "            \"mean\": mean(bst_dists),\n",
    "            \"median\": median(bst_dists),\n",
    "            \"stdev\": stdev(bst_dists),\n",
    "            \"ci\": bst_ci,\n",
    "        },\n",
    "        \"worst\": {\n",
    "            \"dists\": wrst_dists,\n",
    "            \"mean\": mean(wrst_dists),\n",
    "            \"median\": median(wrst_dists),\n",
    "            \"stdev\": stdev(wrst_dists),\n",
    "            \"ci\": wrst_ci,\n",
    "        },\n",
    "        \"overlap\": ci_overlap(*bst_ci, *wrst_ci),\n",
    "        \"ci_alpha\": alpha,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vKNNfB1PzN3n"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def data_snooping_analysis(output_path, n_exp=30, pop=1_000, n_samp=100):\n",
    "    datasets = [\n",
    "        (\"agab\", get_agab_dfs), (\"agraw\", get_agraw_dfs),\n",
    "        (\"bfsm\", get_bfsm_dfs), (\"bfmed\", get_bfmed_dfs),\n",
    "        (\"codesum\", get_codesum_dfs), (\"muts\", get_muts_dfs)\n",
    "    ]\n",
    "\n",
    "    for name, ds in datasets:\n",
    "        results = run_experiments(ds, n_exp=n_exp, pop=pop, n_samp=n_samp)\n",
    "        with open(output_path/f\"{name}_results.json\", 'w') as json_file:\n",
    "            json.dump(results, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 16s, sys: 58.7 s, total: 26min 14s\n",
      "Wall time: 25min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_path = Path(\"overlap_results\")\n",
    "data_snooping_analysis(output_path, n_exp=30, pop=1_000, n_samp=100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNityJEDEc4OytJq9Ix07Bo",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1GIMWEhu_nzDpS7ZWovhKJeVJ2O4nL4xw",
   "name": "scratch01_overlap_eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
